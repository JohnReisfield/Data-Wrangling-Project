{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnreisfield/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, ttest_ind\n",
    "import pandas as pd\n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver.chrome.service import Service  \n",
    "from selenium.webdriver.common.by import By  \n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "from webdriver_manager.chrome import ChromeDriverManager  \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time  \n",
    "import random  \n",
    "import matplotlib.pyplot as plt\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ChromeDriver using webdriver_manager\n",
    "chrome_options = Options()  # Initialize Chrome options (optional)\n",
    "service = Service(ChromeDriverManager().install())  # Install and set up ChromeDriver as a service\n",
    "\n",
    "# Create a ChromeDriver instance\n",
    "browser = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Open the website\n",
    "url = 'https://www.nhl.com/stats/teams?aggregate=0&reportType=season&seasonFrom=20112012&seasonTo=20232024&gameType=2&sort=a_seasonId&page=0&pageSize=50'\n",
    "browser.get(url)\n",
    "\n",
    "# Maximize the browser window for better visibility\n",
    "browser.maximize_window()\n",
    "\n",
    "# Wait a random time between 3-7 seconds before starting\n",
    "time.sleep(random.uniform(3, 7))\n",
    "\n",
    "team= []\n",
    "season= []\n",
    "games_played= []\n",
    "wins= []\n",
    "losses= []\n",
    "overtime_losses= []\n",
    "points= []\n",
    "point_perc= []\n",
    "gf= []\n",
    "ga= []\n",
    "\n",
    "\n",
    "def scrape_page():\n",
    "    # Find rows\n",
    "    rows = browser.find_elements(By.XPATH, '//tbody[@class=\"rt-tbody\"]/tr')\n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            # Locate all columns in the current row\n",
    "            cols = row.find_elements(By.XPATH, './/td')\n",
    "            team.append(cols[1].text)  # Second column: Team\n",
    "            season.append(cols[2].text)  # Third column: Season\n",
    "            games_played.append(cols[3].text)       # Fourth column: GP\n",
    "            wins.append(cols[4].text)               # Fifth column: Wins\n",
    "            losses.append(cols[5].text)             # Sixth column: Losses\n",
    "            overtime_losses.append(cols[7].text)    # Eighth column: OT Losses\n",
    "            points.append(cols[8].text)             # Ninth column: Points\n",
    "            point_perc.append(cols[9].text)         # Tenth column: Point Percentage\n",
    "            gf.append(cols[13].text)                # Fourteenth column: Goals For\n",
    "            ga.append(cols[14].text)                # Fifteenth column: Goals Against\n",
    "        except IndexError:\n",
    "            print(f\"Row {i} does not have enough columns. Skipping.\")\n",
    "\n",
    "while True:\n",
    "    scrape_page()  # Scrape the current page\n",
    "    try:\n",
    "        # Wait for the Next button\n",
    "        next_button = WebDriverWait(browser, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//*[@id=\"season-tabpanel\"]/span/nav/button[2]'))\n",
    "        )\n",
    "        \n",
    "        # Scroll down\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_button)\n",
    "        \n",
    "        try:\n",
    "                    # Retry clicking\n",
    "                    next_button.click()\n",
    "        except ElementClickInterceptedException:\n",
    "                    print(\"ElementClickInterceptedException: Retrying click after scrolling\")\n",
    "                    time.sleep(1)  # Wait \n",
    "                    browser.execute_script(\"window.scrollBy(0, 300);\")  # Scroll down\n",
    "                    browser.execute_script(\"arguments[0].click();\", next_button)\n",
    "                    time.sleep(random.uniform(3, 7))  # Wait for the next page to load\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout waiting for Next\")\n",
    "        break\n",
    "    except NoSuchElementException:\n",
    "        print(\"No more pages to scrape\")\n",
    "        break\n",
    "browser.quit()  # Close the browser after scraping\n",
    "# Convert to df\n",
    "data = {\n",
    "    'Team': team,\n",
    "    'Season': season,\n",
    "    'Games Played': games_played,\n",
    "    'Wins': wins,\n",
    "    'Losses': losses,\n",
    "    'Overtime Losses': overtime_losses,\n",
    "    'Points': points,\n",
    "    'Point Percentage': point_perc,\n",
    "    'Goals For': gf,\n",
    "    'Goals Against': ga\n",
    "}\n",
    "stats = pd.DataFrame(data)  \n",
    "\n",
    "\n",
    "# Convert specific columns to float64\n",
    "columns_to_convert = [\n",
    "    'Games Played', 'Wins', 'Losses', 'Overtime Losses',\n",
    "    'Points', 'Point Percentage', 'Goals For', 'Goals Against'\n",
    "]\n",
    "for column in columns_to_convert:\n",
    "    stats[column] = stats[column].astype('float64')\n",
    "\n",
    "stats['Season'] = stats['Season'].astype(str)\n",
    "\n",
    "# Ensure column headers are set correctly\n",
    "stats.columns = ['Team', 'Season', 'Games Played', 'Wins', 'Losses', 'Overtime Losses', 'Points', 'Point Percentage', 'Goals For', 'Goals Against']\n",
    "stats['Season'] = stats['Season'].str.split('-').str[0]\n",
    "# Display the DataFrame to verify\n",
    "print(stats.head())\n",
    "\n",
    "stats.to_csv('nhl_stats.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
